{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ac618-290e-446b-9745-26b83b89ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "** test only **\n",
    "parameters:\n",
    "    csv_data: all data\n",
    "    signal_len = 1*22051\n",
    "    record_len = 26\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e33df3-9a7a-4dfd-be50-7b1ecb33551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8dc9bc7-0bcf-476a-b64f-e1d646e4ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir1 = Path(r'..\\dataset\\test\\npz_fft_public')\n",
    "data_dir2 = Path(r'..\\dataset\\test\\npz_fft_private')\n",
    "data_json1 = r'..\\dataset\\test\\data_list_public_20230511.json'\n",
    "data_json2 = r'..\\dataset\\test\\data_list_private_20230517.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3cb2bdf-6ac3-404c-bc3b-91923505f0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500\n"
     ]
    }
   ],
   "source": [
    "with open(data_json1) as f:\n",
    "    data_files1 = json.load(f)['test']\n",
    "with open(data_json2) as f:\n",
    "    data_files2 = json.load(f)['test']\n",
    "print(len(data_files1), len(data_files2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a995e4bf-7cf8-4c20-a0f0-1db42664c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = []\n",
    "for v in data_files1:\n",
    "    test_files.append(v)\n",
    "for v in data_files2:\n",
    "    test_files.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d207b1df-bb9a-484a-ad63-2f5d183f9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_len = 1*22051 # length of signal\n",
    "record_len = 26 # length of record\n",
    "\n",
    "def z_score(x):\n",
    "    return (x-x.mean())/x.std()\n",
    "\n",
    "def read_csv_data(csv_data):\n",
    "    record = []\n",
    "    for k, v in csv_data.items():\n",
    "        if k == 'ID':\n",
    "            continue\n",
    "        elif k == 'Sex':\n",
    "            v = float(v)-1 # 1~2 to 0~1\n",
    "        elif k == 'Age':\n",
    "            v = float(v)/50\n",
    "        elif k == 'Voice handicap index - 10':\n",
    "            v = float(v)/40\n",
    "        else:\n",
    "            v = float(v)\n",
    "        record.append(v)\n",
    "    record = z_score(np.array(record)).astype(np.float32)\n",
    "    \n",
    "    return record\n",
    "\n",
    "def read_npz_file(file):\n",
    "    npz_data = np.load(file, allow_pickle=True)\n",
    "    signal = z_score(npz_data['signal']).astype(np.float32)\n",
    "    record = read_csv_data(npz_data['csv_data'].item())\n",
    "    \n",
    "    return (signal, record)\n",
    "\n",
    "def cut_pad_signal(signal, length=signal_len, mode='middle'):\n",
    "    if len(signal) > length:\n",
    "        cut_len = len(signal)-length\n",
    "        if mode == 'middle': # cut from middle\n",
    "            mid = cut_len//2\n",
    "            return signal[mid:mid+length]\n",
    "        elif mode == 'random': # random cut\n",
    "            rand = np.random.randint(cut_len)\n",
    "            return signal[rand:rand+length]\n",
    "    else:\n",
    "        pad_len = length-len(signal)\n",
    "        signal = np.pad(signal, (0, pad_len)) \n",
    "        return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1778413-1742-4b57-8f04-6389bb3223d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 500/500 [00:03<00:00, 131.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 500/500 [00:03<00:00, 135.53it/s]\n"
     ]
    }
   ],
   "source": [
    "test_info = {i: [] for i in ['input_data']}\n",
    "\n",
    "for file in tqdm(data_files1):\n",
    "    input_data = read_npz_file(data_dir1/file)\n",
    "    test_info['input_data'].append(input_data)\n",
    "for file in tqdm(data_files2):\n",
    "    input_data = read_npz_file(data_dir2/file)\n",
    "    test_info['input_data'].append(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf0c3e9-9988-40cd-9249-d7f22000cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload model\n",
    "model_name = 'm202_MultiOutput_20230518_114418'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd00dac-bab7-4080-8d1d-df047cc58aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m202_MultiOutput_20230518_114418\n"
     ]
    }
   ],
   "source": [
    "from models import m202_MultiOutput\n",
    "model = m202_MultiOutput(record_len).cuda()\n",
    "print(model_name)\n",
    "\n",
    "weights_dir = Path('weights', model_name)\n",
    "results_dir = Path('test_results', model_name)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aa4c537-e5a2-412f-b0e7-033939a59659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_evaluate(chosen):\n",
    "    model.eval()\n",
    "    results = []\n",
    "\n",
    "    pbar = tqdm(test_data, unit='batch')\n",
    "    for batch in pbar:\n",
    "        inputs = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs[0], inputs[1])\n",
    "            \n",
    "        preds = torch.max(outputs[chosen], 1)[1]\n",
    "        results += [p+1 for p in preds.tolist()]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6966b61-0219-4660-b20b-9685465a387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationDataset(Dataset):\n",
    "    def __init__(self, data_type, input_data):\n",
    "        self.data_type = data_type\n",
    "        self.input_data = input_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        signal = self.input_data[index][0]\n",
    "        record = self.input_data[index][1]\n",
    "        if self.data_type == 'fixed': # fixed length\n",
    "            signal = torch.tensor(cut_pad_signal(signal), dtype=torch.float32).cuda().unsqueeze(0)\n",
    "        elif self.data_type == 'original': # original length\n",
    "            signal = torch.tensor(signal, dtype=torch.float32).cuda().unsqueeze(0)\n",
    "            \n",
    "        record = torch.tensor(record, dtype=torch.float32).cuda()\n",
    "        return (signal, record)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdd252f2-205b-4f80-9a70-41e9398674e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed length results\n",
    "batch_size = 64\n",
    "test_data = DataLoader(EvaluationDataset('fixed', test_info['input_data']),\n",
    "                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5677aab3-0d30-4239-8654-33f458c60817",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_uar-0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 16.37batch/s]\n"
     ]
    }
   ],
   "source": [
    "weights_file = 'best_uar-0'\n",
    "print(f'{weights_file}:')\n",
    "model.load_state_dict(torch.load(weights_dir/f'{weights_file}.pth'))\n",
    "results = start_evaluate(0)\n",
    "\n",
    "df = pd.DataFrame(results, [f.split('.')[0] for f in test_files])\n",
    "df.to_csv(results_dir/'fixed_length-chosen_outputs0.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca3ce3-e955-4a74-b14a-177e28458fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1-13",
   "language": "python",
   "name": "torch_1-13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
